{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZNyfW5el9FB7"
   },
   "source": [
    "### The German Traffic Sign Benchmark\n",
    "\n",
    "Student Name 1: Panagiotis Michalopoulos\n",
    "\n",
    "Student Name 2: Filip Finfando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f2t23RDU9FB9"
   },
   "source": [
    "Download full data set from http://benchmark.ini.rub.de/?section=gtsdb&subsection=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 39891
    },
    "colab_type": "code",
    "id": "UJyg3OTS9FB_",
    "outputId": "fb3f65e3-3656-493c-d255-fbd893baa516"
   },
   "outputs": [],
   "source": [
    "!wget -c http://benchmark.ini.rub.de/Dataset_GTSDB/FullIJCNN2013.zip\n",
    "!unzip FullIJCNN2013.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pt81Eft39FCF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "IMG_HEIGHT = 600\n",
    "#SIGN_SIZE = (224, 224)\n",
    "SIGN_SIZE = (32, 32)\n",
    "\n",
    "# Function for reading the images\n",
    "def readImages(rootpath, images_range, signs_range):\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "    Arguments: path to the traffic sign data, for example 'FullIJCNN2013'\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = {} # original image\n",
    "    scales = {} # original scale\n",
    "    for num in images_range:\n",
    "        filename = rootpath + '/' + \"{:05d}\".format(num) + '.ppm'\n",
    "        img = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "        #img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "        scale = IMG_HEIGHT / float(img.shape[0])\n",
    "        img_resized = cv2.resize(img, (int(img.shape[1]*scale),int(img.shape[0]*scale)))\n",
    "        images.setdefault(filename,[]).append(img_resized)\n",
    "        scales.setdefault(filename,[]).append(scale)\n",
    "\n",
    "    files = [] # filenames\n",
    "    signs = [] # traffic sign image\n",
    "    bboxes = [] # corresponding box detection\n",
    "    labels = [] # traffic sign type\n",
    "    data = np.genfromtxt(rootpath + '/' + 'gt.txt', delimiter=';', dtype=str, usecols=range(0, 6))\n",
    "    for elem in signs_range:\n",
    "        filename = rootpath + '/' + data[elem][0]\n",
    "        img = images.get(filename)[0]\n",
    "        scale = scales.get(filename)[0]\n",
    "        bbox = np.array([int(data[elem][1]), int(data[elem][2]), int(data[elem][3]), int(data[elem][4])]) * scale\n",
    "        sign = img[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
    "        sign_resized = cv2.resize(sign, SIGN_SIZE)\n",
    "        files.append(filename)\n",
    "        signs.append(sign_resized)\n",
    "        bboxes.append(bbox)\n",
    "        labels.append(data[elem][5])\n",
    "    return images, files, signs, bboxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugfSjhY69FCH"
   },
   "outputs": [],
   "source": [
    "# The German Traffic Sign Recognition Benchmark\n",
    "train_images, train_files, train_signs, train_bboxes, train_labels = readImages('FullIJCNN2013', range(0,600), range(0,852))\n",
    "test_images, test_files, test_signs, test_bboxes, test_labels = readImages('FullIJCNN2013', range(600,900), range(852,1213))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "zxI01qsB9FCJ",
    "outputId": "e8dd5869-a9ae-458e-dc33-d8b3d1a624ba"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Show examples from each class\n",
    "class_names = np.unique(train_labels)\n",
    "num_classes = len(class_names)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "for i in range(num_classes):\n",
    "    ax = fig.add_subplot(6, 9, 1 + i, xticks=[], yticks=[])\n",
    "    ax.set_title(class_names[i])\n",
    "    indices = np.where(np.isin(train_labels, class_names[i]))[0]\n",
    "    plt.imshow(cv2.cvtColor(train_signs[int(np.random.choice(indices, 1))], cv2.COLOR_BGR2RGB))\n",
    "    #plt.imshow(train_signs[int(np.random.choice(indices, 1))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEpCoIRY9FCM"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_files, train_signs, train_bboxes, train_labels = shuffle(train_files, train_signs, train_bboxes, train_labels)\n",
    "# plt.imshow(cv2.cvtColor(train_images.get(train_files[0])[0], cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "# plt.imshow(cv2.cvtColor(train_signs[0], cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "# print(train_bboxes[0])\n",
    "# print(train_labels[0])\n",
    "\n",
    "# Data pre-processing\n",
    "tr_signs = np.array(train_signs)[0:600]\n",
    "tr_labels = np.array(train_labels)[0:600]\n",
    "va_signs = np.array(train_signs)[600:852]\n",
    "va_labels = np.array(train_labels)[600:852]\n",
    "te_signs = np.array(test_signs)\n",
    "te_labels = np.array(test_labels)\n",
    "\n",
    "tr_signs = tr_signs.astype('float32')\n",
    "va_signs = va_signs.astype('float32')\n",
    "te_signs = te_signs.astype('float32')\n",
    "tr_signs /= 255.0\n",
    "va_signs /= 255.0\n",
    "te_signs /= 255.0\n",
    "\n",
    "from keras.utils import np_utils\n",
    "tr_labels = np_utils.to_categorical(tr_labels, num_classes)\n",
    "va_labels = np_utils.to_categorical(va_labels, num_classes)\n",
    "te_labels = np_utils.to_categorical(te_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pK9aqvC39FCP"
   },
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUELCOIA9FCT"
   },
   "source": [
    "## Assignment 3.2: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 733
    },
    "colab_type": "code",
    "id": "u3Dpv_oU9FCU",
    "outputId": "9b12fd75-d581-4791-b34f-608a10b279b7"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers, optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "#cnn = Sequential()\n",
    "\n",
    "#cnn.add(Conv2D(filters=32, strides=(2, 2), kernel_size=(5, 5), padding='same', input_shape=(SIGN_SIZE[0], SIGN_SIZE[1], 3), kernel_initializer='glorot_normal'))\n",
    "#cnn.add(BatchNormalization())\n",
    "#cnn.add(Activation('relu'))\n",
    "#cnn.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "#cnn.add(Dropout(0.1))\n",
    "\n",
    "#cnn.add(Conv2D(filters=64, strides=(2, 2), kernel_size=(5, 5), padding='same', kernel_initializer='glorot_normal'))\n",
    "#cnn.add(BatchNormalization())\n",
    "#cnn.add(Activation('relu'))\n",
    "#cnn.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "#cnn.add(Dropout(0.2))\n",
    "\n",
    "#cnn.add(Conv2D(filters=128, strides=(2, 2), kernel_size=(5, 5), padding='same', kernel_initializer='glorot_normal'))\n",
    "#cnn.add(BatchNormalization())\n",
    "#cnn.add(Activation('relu'))\n",
    "#cnn.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "#cnn.add(Dropout(0.3))\n",
    "\n",
    "#cnn.add(Flatten())\n",
    "\n",
    "#cnn.add(Dense(1024, kernel_initializer='glorot_normal'))\n",
    "#cnn.add(BatchNormalization())\n",
    "#cnn.add(Activation('relu'))\n",
    "#cnn.add(Dropout(0.7))\n",
    "\n",
    "#cnn.add(Dense(num_classes))\n",
    "#cnn.add(Activation('softmax'))\n",
    "\n",
    "cnn = Sequential()\n",
    "## If You preprocessed with gray scaling and local histogram equivalization then input_shape = (32,32,1) else (32,32,3)\n",
    "cnn.add(Conv2D(32, kernel_size=(3, 3),activation='relu', input_shape=(SIGN_SIZE[0], SIGN_SIZE[1], 3)))\n",
    "#cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Dropout(0.25))\n",
    "cnn.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#opt = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "cnn.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1431
    },
    "colab_type": "code",
    "id": "WoVkm0869FCX",
    "outputId": "e6aa4739-6335-40b3-ec4b-41e7052a00b0"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=0, mode='auto')\n",
    "\n",
    "data = cnn.fit(tr_signs, tr_labels, batch_size=16, epochs=100, verbose=2, validation_data=(va_signs, va_labels), callbacks=[tensorboard, early_stopping])\n",
    "\n",
    "start = time()\n",
    "loss, acc = cnn.evaluate(te_signs, te_labels, verbose=0)\n",
    "end = time()\n",
    "print('CNN took ' + str(end - start) + ' seconds')\n",
    "print('Test loss: ' + str(loss) + ' - Accuracy: ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "oEdZqsULmP36",
    "outputId": "8e59a744-4530-4dda-fe2b-002d274e12e0"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(data.history['acc'])\n",
    "plt.plot(data.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(data.history['loss'])\n",
    "plt.plot(data.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1369
    },
    "colab_type": "code",
    "id": "IDCHmLFS9FCb",
    "outputId": "e71b8e55-b6dd-42b9-97aa-a4686176af26"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(len(tr_signs))\n",
    "tr_signs_aug = np.array(tr_signs, copy=True) \n",
    "tr_labels_aug = np.array(tr_labels, copy=True)\n",
    "\n",
    "#datagen = ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, fill_mode='nearest')\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                             featurewise_std_normalization=False,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2,\n",
    "                             shear_range=0.1,\n",
    "                             rotation_range=10.)\n",
    "\n",
    "datagen.fit(tr_signs_aug, augment=True)\n",
    "\n",
    "# Concatenating the old data with the augmented data\n",
    "tr_signs_aug  = np.concatenate((tr_signs, tr_signs_aug), axis=0)\n",
    "tr_labels_aug  = np.concatenate((tr_labels, tr_labels_aug), axis=0)\n",
    "\n",
    "print(len(tr_signs_aug))\n",
    "\n",
    "for x_batch, y_batch in datagen.flow(tr_signs_aug, tr_labels_aug, batch_size=9):\n",
    "    # create a grid of 3x3 images\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    for i in range(0, 9):\n",
    "        ax = fig.add_subplot(3, 3, 1 + i, xticks=[], yticks=[])\n",
    "        ax.set_title(np.argmax(y_batch[i]))\n",
    "        plt.imshow(cv2.cvtColor(x_batch[i], cv2.COLOR_BGR2RGB))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break\n",
    "\n",
    "train_steps = int(len(tr_signs_aug) / 16)\n",
    "valid_steps = int(len(va_signs) / 16)\n",
    "data = cnn.fit_generator(datagen.flow(tr_signs_aug, tr_labels_aug, batch_size=16), epochs=100, steps_per_epoch=train_steps, verbose=2, validation_data=(va_signs, va_labels), validation_steps=valid_steps, callbacks=[tensorboard, early_stopping])\n",
    "\n",
    "start = time()\n",
    "loss, acc = cnn.evaluate(te_signs, te_labels, verbose=0)\n",
    "end = time()\n",
    "print('CNN took ' + str(end - start) + ' seconds')\n",
    "print('Test loss: ' + str(loss) + ' - Accuracy: ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "azoJqz2f9FCe",
    "outputId": "6a4c6396-96a8-4e8a-ca3e-255e8c9e589f"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(data.history['acc'])\n",
    "plt.plot(data.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(data.history['loss'])\n",
    "plt.plot(data.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ZNyfW5el9FB7"
   ],
   "name": "Assignment_3_2_greyscale.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
