{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "718GBnHeSBsx"
   },
   "source": [
    "### The German Traffic Sign Benchmark\n",
    "\n",
    "Student Name 1: Panagiotis Michalopoulos\n",
    "\n",
    "Student Name 2: Filip Finfando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yXMJLE-tSBsy"
   },
   "source": [
    "Download full data set from http://benchmark.ini.rub.de/?section=gtsdb&subsection=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjVJoOb8SBtB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "IMG_HEIGHT = 600\n",
    "#SIGN_SIZE = (224, 224)\n",
    "SIGN_SIZE = (32, 32)\n",
    "\n",
    "# Function for reading the images\n",
    "def readImages(rootpath, images_range, signs_range):\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "    Arguments: path to the traffic sign data, for example 'FullIJCNN2013'\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = {} # original image\n",
    "    scales = {} # original scale\n",
    "    for num in images_range:\n",
    "        filename = rootpath + '/' + \"{:05d}\".format(num) + '.ppm'\n",
    "        img = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        scale = IMG_HEIGHT / float(img.shape[0])\n",
    "        img_resized = cv2.resize(img, (int(img.shape[1]*scale),int(img.shape[0]*scale)))\n",
    "        images.setdefault(filename,[]).append(img_resized)\n",
    "        scales.setdefault(filename,[]).append(scale)\n",
    "\n",
    "    files = [] # filenames\n",
    "    signs = [] # traffic sign image\n",
    "    bboxes = [] # corresponding box detection\n",
    "    labels = [] # traffic sign type\n",
    "    data = np.genfromtxt(rootpath + '/' + 'gt.txt', delimiter=';', dtype=str, usecols=range(0, 6))\n",
    "    for elem in signs_range:\n",
    "        filename = rootpath + '/' + data[elem][0]\n",
    "        img = images.get(filename)[0]\n",
    "        scale = scales.get(filename)[0]\n",
    "        bbox = np.array([int(data[elem][1]), int(data[elem][2]), int(data[elem][3]), int(data[elem][4])]) * scale\n",
    "        sign = img[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
    "        sign_resized = cv2.resize(sign, SIGN_SIZE)\n",
    "        files.append(filename)\n",
    "        signs.append(sign_resized)\n",
    "        bboxes.append(bbox)\n",
    "        labels.append(data[elem][5])\n",
    "    return images, files, signs, bboxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWA9VZTuSBtE"
   },
   "outputs": [],
   "source": [
    "# The German Traffic Sign Recognition Benchmark\n",
    "train_images, train_files, train_signs, train_bboxes, train_labels = readImages('../FullIJCNN2013', range(0,600), range(0,852))\n",
    "test_images, test_files, test_signs, test_bboxes, test_labels = readImages('../FullIJCNN2013', range(600,900), range(852,1213))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 212050,
     "status": "ok",
     "timestamp": 1555253377336,
     "user": {
      "displayName": "Filip Finfando",
      "photoUrl": "https://lh4.googleusercontent.com/-zesJ_QflPgA/AAAAAAAAAAI/AAAAAAABsIc/Iqwtrg0Bzwo/s64/photo.jpg",
      "userId": "16121761162030927360"
     },
     "user_tz": -120
    },
    "id": "ZhX1ebSxSBtH",
    "outputId": "59cbc03d-6eb1-405b-e9c4-05f1b78b46a1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Show examples from each class\n",
    "class_names = np.unique(train_labels)\n",
    "num_classes = len(class_names)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "for i in range(num_classes):\n",
    "    ax = fig.add_subplot(6, 9, 1 + i, xticks=[], yticks=[])\n",
    "    ax.set_title(class_names[i])\n",
    "    indices = np.where(np.isin(train_labels, class_names[i]))[0]\n",
    "    plt.imshow(cv2.cvtColor(train_signs[int(np.random.choice(indices, 1))], cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 210288,
     "status": "ok",
     "timestamp": 1555253379517,
     "user": {
      "displayName": "Filip Finfando",
      "photoUrl": "https://lh4.googleusercontent.com/-zesJ_QflPgA/AAAAAAAAAAI/AAAAAAABsIc/Iqwtrg0Bzwo/s64/photo.jpg",
      "userId": "16121761162030927360"
     },
     "user_tz": -120
    },
    "id": "QIcE16qnSBtL",
    "outputId": "cb3624b0-b8c5-41ae-9bb8-f3e2a7ca1f94"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_files, train_signs, train_bboxes, train_labels = shuffle(train_files, train_signs, train_bboxes, train_labels)\n",
    "# plt.imshow(cv2.cvtColor(train_images.get(train_files[0])[0], cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "# plt.imshow(cv2.cvtColor(train_signs[0], cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "# print(train_bboxes[0])\n",
    "# print(train_labels[0])\n",
    "\n",
    "# Data pre-processing\n",
    "tr_signs = np.array(train_signs)[0:600]\n",
    "tr_labels = np.array(train_labels)[0:600]\n",
    "va_signs = np.array(train_signs)[600:852]\n",
    "va_labels = np.array(train_labels)[600:852]\n",
    "te_signs = np.array(test_signs)\n",
    "te_labels = np.array(test_labels)\n",
    "\n",
    "tr_signs = tr_signs.astype('float32')\n",
    "va_signs = va_signs.astype('float32')\n",
    "te_signs = te_signs.astype('float32')\n",
    "tr_signs /= 255.0\n",
    "va_signs /= 255.0\n",
    "te_signs /= 255.0\n",
    "\n",
    "from keras.utils import np_utils\n",
    "tr_labels = np_utils.to_categorical(tr_labels, num_classes)\n",
    "va_labels = np_utils.to_categorical(va_labels, num_classes)\n",
    "te_labels = np_utils.to_categorical(te_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "unwgrhVSSBtP"
   },
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j0eVsxuvSBtS"
   },
   "source": [
    "## Assignment 3.4: Traffic sign detection\n",
    "\n",
    "sudo pip install Keras==2.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B78KOl60SBtT"
   },
   "outputs": [],
   "source": [
    "ANCHOR_RATIOS = (0.5, 1.0, 2.0)\n",
    "ANCHOR_STRIDE = 16\n",
    "ANCHOR_SIZES = (32, 64, 128, 256, 512)\n",
    "MAX_SIZE = 1344\n",
    "MIN_SIZE = 0\n",
    "\n",
    "# Parameters to play with to modify the number of proposal in each image\n",
    "TEST_PRE_NMS_TOPK = 8000 # The maximum number of positive samples taken during proposal generation, pre NMS\n",
    "TEST_POST_NMS_TOPK = 1000 # The maximum number of positive samples taken during proposal generation, post NMS\n",
    "PROPOSAL_NMS_THRESH = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfF1WOotSBtV"
   },
   "outputs": [],
   "source": [
    "\"\"\"Operations for [N, 4] numpy arrays representing bounding boxes.\n",
    "Example box operations that are supported:\n",
    "  * Areas: compute bounding box areas\n",
    "  * IOU: pairwise intersection-over-union scores\n",
    "\"\"\"\n",
    "def area(boxes):\n",
    "    \"\"\"Computes area of boxes.\n",
    "    Args:\n",
    "    boxes: Numpy array with shape [N, 4] holding N boxes\n",
    "    Returns:\n",
    "    a numpy array with shape [N*1] representing box areas\n",
    "    \"\"\"\n",
    "    return (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "\n",
    "def intersection(boxes1, boxes2):\n",
    "    \"\"\"Compute pairwise intersection areas between boxes.\n",
    "    Args:\n",
    "    boxes1: a numpy array with shape [N, 4] holding N boxes\n",
    "    boxes2: a numpy array with shape [M, 4] holding M boxes\n",
    "    Returns:\n",
    "    a numpy array with shape [N*M] representing pairwise intersection area\n",
    "    \"\"\"\n",
    "    [x_min1, y_min1, x_max1, y_max1] = np.split(boxes1, 4, axis=1)\n",
    "    [x_min2, y_min2, x_max2, y_max2] = np.split(boxes2, 4, axis=1)\n",
    "    all_pairs_min_ymax = np.minimum(y_max1, np.transpose(y_max2))\n",
    "    all_pairs_max_ymin = np.maximum(y_min1, np.transpose(y_min2))\n",
    "    intersect_heights = np.maximum(np.zeros(all_pairs_max_ymin.shape, dtype='f4'),all_pairs_min_ymax - all_pairs_max_ymin)\n",
    "    all_pairs_min_xmax = np.minimum(x_max1, np.transpose(x_max2))\n",
    "    all_pairs_max_xmin = np.maximum(x_min1, np.transpose(x_min2))\n",
    "    intersect_widths = np.maximum(np.zeros(all_pairs_max_xmin.shape, dtype='f4'),all_pairs_min_xmax - all_pairs_max_xmin)\n",
    "    return intersect_heights * intersect_widths\n",
    "\n",
    "def iou(boxes1, boxes2):\n",
    "    \"\"\"Computes pairwise intersection-over-union between box collections.\n",
    "    Args:\n",
    "    boxes1: a numpy array with shape [N, 4] holding N boxes.\n",
    "    boxes2: a numpy array with shape [M, 4] holding M boxes.\n",
    "    Returns:\n",
    "    a numpy array with shape [N, M] representing pairwise iou scores.\n",
    "    \"\"\"\n",
    "    intersect = intersection(boxes1, boxes2)\n",
    "    area1 = area(boxes1)\n",
    "    area2 = area(boxes2)\n",
    "    union = np.expand_dims(area1, axis=1) + np.expand_dims(area2, axis=0) - intersect\n",
    "    return intersect / union\n",
    "\n",
    "def ioa(boxes1, boxes2):\n",
    "    \"\"\"Computes pairwise intersection-over-area between box collections.\n",
    "    Intersection-over-area (ioa) between two boxes box1 and box2 is defined as\n",
    "    their intersection area over box2's area. Note that ioa is not symmetric,\n",
    "    that is, IOA(box1, box2) != IOA(box2, box1).\n",
    "    Args:\n",
    "    boxes1: a numpy array with shape [N, 4] holding N boxes.\n",
    "    boxes2: a numpy array with shape [M, 4] holding N boxes.\n",
    "    Returns:\n",
    "    a numpy array with shape [N, M] representing pairwise ioa scores.\n",
    "    \"\"\"\n",
    "    intersect = intersection(boxes1, boxes2)\n",
    "    inv_areas = np.expand_dims(1.0 / area(boxes2), axis=0)\n",
    "    return intersect * inv_areas\n",
    "\n",
    "def clip_boxes(bboxes, clip_box, alpha):\n",
    "    \"\"\"\n",
    "    This function clip the bboxes to the border of the image\n",
    "\n",
    "    :param bboxes: array of shape (Nx4) containing the coordinates of the bboxes\n",
    "                in the format: xmin, ymin, xmax, ymax.\n",
    "    :param clip_box: array of shape (4,) containing the coordinates of the image\n",
    "                in the format: xmin, ymin, xmax ymax.\n",
    "    :param alpha:float, minimum threshold of area acepted. If a clipped bbpx\n",
    "                    have an relative area (wrt their original area) less than\n",
    "                    alpha, it is discarded.\n",
    "    :return: numpy array Nx4 of the clipped bboxes with their new coordinates\n",
    "            in the format xmin, ymin, xmax, ymax.\n",
    "    \"\"\"\n",
    "    areas = area(bboxes)\n",
    "    bboxes[:, 0] = np.maximum(bboxes[:, 0], clip_box[0])\n",
    "    bboxes[:, 1] = np.maximum(bboxes[:, 1], clip_box[1])\n",
    "    bboxes[:, 2] = np.minimum(bboxes[:, 2], clip_box[2])\n",
    "    bboxes[:, 3] = np.minimum(bboxes[:, 3], clip_box[3])\n",
    "    new_areas = area(bboxes)\n",
    "    delta_area = (areas - new_areas) / areas\n",
    "    mask = np.where(delta_area < 1 - alpha)\n",
    "    bboxes = bboxes[mask[0]]\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkd15njwSBtZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def generate_anchors(base_size=16, ratios=[0.5, 1, 2], scales=2**np.arange(3, 6)):\n",
    "    \"\"\"\n",
    "    Generate anchor (reference) windows by enumerating aspect ratios X\n",
    "    scales wrt a reference (0, 0, 15, 15) window.\n",
    "    \"\"\"\n",
    "    base_anchor = np.array([1, 1, base_size, base_size], dtype='float32') - 1\n",
    "    ratio_anchors = _ratio_enum(base_anchor, ratios)\n",
    "    anchors = np.vstack([_scale_enum(ratio_anchors[i, :], scales) for i in range(ratio_anchors.shape[0])])\n",
    "    return anchors\n",
    "\n",
    "def _whctrs(anchor):\n",
    "    \"\"\"\n",
    "    Return width, height, x center, and y center for an anchor (window).\n",
    "    \"\"\"\n",
    "    w = anchor[2] - anchor[0] + 1\n",
    "    h = anchor[3] - anchor[1] + 1\n",
    "    x_ctr = anchor[0] + 0.5 * (w - 1)\n",
    "    y_ctr = anchor[1] + 0.5 * (h - 1)\n",
    "    return w, h, x_ctr, y_ctr\n",
    "\n",
    "def _mkanchors(ws, hs, x_ctr, y_ctr):\n",
    "    \"\"\"\n",
    "    Given a vector of widths (ws) and heights (hs) around a center\n",
    "    (x_ctr, y_ctr), output a set of anchors (windows).\n",
    "    \"\"\"\n",
    "    ws = ws[:, np.newaxis]\n",
    "    hs = hs[:, np.newaxis]\n",
    "    anchors = np.hstack((x_ctr - 0.5 * (ws - 1), y_ctr - 0.5 * (hs - 1), x_ctr + 0.5 * (ws - 1), y_ctr + 0.5 * (hs - 1)))\n",
    "    return anchors\n",
    "\n",
    "def _ratio_enum(anchor, ratios):\n",
    "    \"\"\"\n",
    "    Enumerate a set of anchors for each aspect ratio wrt an anchor.\n",
    "    \"\"\"\n",
    "    w, h, x_ctr, y_ctr = _whctrs(anchor)\n",
    "    size = w * h\n",
    "    size_ratios = size / ratios\n",
    "    ws = np.round(np.sqrt(size_ratios))\n",
    "    hs = np.round(ws * ratios)\n",
    "    anchors = _mkanchors(ws, hs, x_ctr, y_ctr)\n",
    "    return anchors\n",
    "\n",
    "def _scale_enum(anchor, scales):\n",
    "    \"\"\"\n",
    "    Enumerate a set of anchors for each scale wrt an anchor.\n",
    "    \"\"\"\n",
    "    w, h, x_ctr, y_ctr = _whctrs(anchor)\n",
    "    ws = w * scales\n",
    "    hs = h * scales\n",
    "    anchors = _mkanchors(ws, hs, x_ctr, y_ctr)\n",
    "    return anchors\n",
    "\n",
    "def get_all_anchors(stride=None, sizes=None):\n",
    "    \"\"\"\n",
    "    Get all anchors in the largest possible image, shifted, floatbox\n",
    "    Args:\n",
    "        stride (int): the stride of anchors.\n",
    "        sizes (tuple[int]): the sizes (sqrt area) of anchors\n",
    "\n",
    "    Returns:\n",
    "        anchors: SxSxNUM_ANCHORx4, where S == ceil(MAX_SIZE/STRIDE), floatbox\n",
    "        The layout in the NUM_ANCHOR dim is NUM_RATIO x NUM_SIZE.\n",
    "\n",
    "    \"\"\"\n",
    "    if stride is None:\n",
    "        stride = ANCHOR_STRIDE\n",
    "    if sizes is None:\n",
    "        sizes = ANCHOR_SIZES\n",
    "    # Generates a NAx4 matrix of anchor boxes in (x1, y1, x2, y2) format. Anchors\n",
    "    # are centered on stride / 2, have (approximate) sqrt areas of the specified\n",
    "    # sizes, and aspect ratios as given.\n",
    "    cell_anchors = generate_anchors(stride, scales=np.array(sizes, dtype=np.float) / stride, ratios=np.array(ANCHOR_RATIOS, dtype=np.float))\n",
    "    # anchors are intbox here.\n",
    "    # anchors at featuremap [0,0] are centered at fpcoor (8,8) (half of stride)\n",
    "    field_size = int(np.ceil(MAX_SIZE / stride))\n",
    "    shifts = np.arange(0, field_size) * stride\n",
    "    shift_x, shift_y = np.meshgrid(shifts, shifts)\n",
    "    shift_x = shift_x.flatten()\n",
    "    shift_y = shift_y.flatten()\n",
    "    shifts = np.vstack((shift_x, shift_y, shift_x, shift_y)).transpose()\n",
    "    K = shifts.shape[0]\n",
    "\n",
    "    A = cell_anchors.shape[0]\n",
    "    field_of_anchors = (\n",
    "        cell_anchors.reshape((1, A, 4)) +\n",
    "        shifts.reshape((1, K, 4)).transpose((1, 0, 2)))\n",
    "    field_of_anchors = field_of_anchors.reshape((field_size, field_size, A, 4))\n",
    "    field_of_anchors = field_of_anchors.astype('float32')\n",
    "    field_of_anchors[:, :, :, [2, 3]] += 1\n",
    "    return field_of_anchors\n",
    "\n",
    "def decode_bbox_target(box_predictions, anchors):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        box_predictions: (..., 4), logits\n",
    "        anchors: (..., 4), floatbox. Must have the same shape\n",
    "\n",
    "    Returns:\n",
    "        box_decoded: (..., 4), float32. With the same shape.\n",
    "    \"\"\"\n",
    "    orig_shape = tf.shape(anchors)\n",
    "    box_pred_txtytwth = tf.reshape(box_predictions, (-1, 2, 2))\n",
    "    box_pred_txty, box_pred_twth = tf.split(box_pred_txtytwth, 2, axis=1)\n",
    "    anchors_x1y1x2y2 = tf.reshape(anchors, (-1, 2, 2))\n",
    "    anchors_x1y1, anchors_x2y2 = tf.split(anchors_x1y1x2y2, 2, axis=1)\n",
    "\n",
    "    waha = anchors_x2y2 - anchors_x1y1\n",
    "    xaya = (anchors_x2y2 + anchors_x1y1) * 0.5\n",
    "    clip = np.log(MAX_SIZE / 16.)\n",
    "    wbhb = tf.exp(tf.minimum(box_pred_twth, clip)) * waha\n",
    "    xbyb = box_pred_txty * waha + xaya\n",
    "    x1y1 = xbyb - wbhb * 0.5\n",
    "    x2y2 = xbyb + wbhb * 0.5\n",
    "    out = tf.concat([x1y1, x2y2], axis=-2)\n",
    "    return tf.reshape(out, orig_shape)\n",
    "\n",
    "def narrow_to_c4(featuremaps, anchor_boxes):\n",
    "    \"\"\"\n",
    "    Slice anchors to the spatial size of this featuremap.\n",
    "    \"\"\"\n",
    "    shape2d = tf.shape(featuremaps)[2:]  # h,w\n",
    "    slice4d = tf.concat([shape2d, [-1, -1]], axis=0)\n",
    "    anchor_boxes = tf.slice(anchor_boxes, [0, 0, 0, 0], slice4d)\n",
    "    return anchor_boxes\n",
    "\n",
    "def clip_boxes(boxes, window, name=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        boxes: nx4, xyxy\n",
    "        window: [h, w]\n",
    "    \"\"\"\n",
    "    boxes = tf.maximum(boxes, 0.0)\n",
    "    m = tf.tile(tf.reverse(window, [0]), [2])  # (4,)\n",
    "    boxes = tf.minimum(boxes, tf.to_float(m), name=name)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_VD5zvviSBtc"
   },
   "outputs": [],
   "source": [
    "def generate_rpn_proposals(boxes_and_scores, img_shape, pre_nms_topk, post_nms_topk):\n",
    "    \"\"\"\n",
    "    Sample RPN proposals by the following steps:\n",
    "    1. Pick top k1 by scores\n",
    "    2. NMS them\n",
    "    3. Pick top k2 by scores. Default k2 == k1, i.e. does not filter the NMS output.\n",
    "\n",
    "    Args:\n",
    "        boxes: nx4 float dtype, the proposal boxes. Decoded to floatbox already\n",
    "        scores: n float, the logits\n",
    "        img_shape: [h, w]\n",
    "        pre_nms_topk, post_nms_topk (int): See above.\n",
    "\n",
    "    Returns:\n",
    "        boxes: kx4 float\n",
    "        scores: k logits\n",
    "    \"\"\"\n",
    "    boxes = boxes_and_scores[0]\n",
    "    scores = boxes_and_scores[1]\n",
    "\n",
    "    assert boxes.shape.ndims == 2, boxes.shape\n",
    "    if post_nms_topk is None:\n",
    "        post_nms_topk = pre_nms_topk\n",
    "\n",
    "    topk = tf.minimum(pre_nms_topk, tf.size(scores))\n",
    "    topk_scores, topk_indices = tf.nn.top_k(scores, k=topk, sorted=False)\n",
    "    topk_boxes = tf.gather(boxes, topk_indices)\n",
    "    topk_boxes = clip_boxes(topk_boxes, img_shape)\n",
    "\n",
    "    topk_boxes_x1y1x2y2 = tf.reshape(topk_boxes, (-1, 2, 2))\n",
    "    topk_boxes_x1y1, topk_boxes_x2y2 = tf.split(topk_boxes_x1y1x2y2, 2, axis=1)\n",
    "    wbhb = tf.squeeze(topk_boxes_x2y2 - topk_boxes_x1y1, axis=1)\n",
    "    valid = tf.reduce_all(wbhb > MIN_SIZE, axis=1)\n",
    "    topk_valid_boxes_x1y1x2y2 = tf.boolean_mask(topk_boxes_x1y1x2y2, valid)\n",
    "    topk_valid_scores = tf.boolean_mask(topk_scores, valid)\n",
    "\n",
    "    topk_valid_boxes_y1x1y2x2 = tf.reshape(tf.reverse(topk_valid_boxes_x1y1x2y2, axis=[2]), (-1, 4), name='nms_input_boxes')\n",
    "    nms_indices = tf.image.non_max_suppression(topk_valid_boxes_y1x1y2x2, topk_valid_scores, max_output_size=post_nms_topk, iou_threshold=PROPOSAL_NMS_THRESH)\n",
    "\n",
    "    topk_valid_boxes = tf.reshape(topk_valid_boxes_x1y1x2y2, (-1, 4))\n",
    "    proposal_boxes = tf.gather(topk_valid_boxes, nms_indices)\n",
    "    proposal_scores = tf.gather(topk_valid_scores, nms_indices)\n",
    "    return [tf.stop_gradient(proposal_boxes, name='boxes'), tf.stop_gradient(proposal_scores, name='scores')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2577
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 194530,
     "status": "error",
     "timestamp": 1555253385285,
     "user": {
      "displayName": "Filip Finfando",
      "photoUrl": "https://lh4.googleusercontent.com/-zesJ_QflPgA/AAAAAAAAAAI/AAAAAAABsIc/Iqwtrg0Bzwo/s64/photo.jpg",
      "userId": "16121761162030927360"
     },
     "user_tz": -120
    },
    "id": "LA7VFoofSBtf",
    "outputId": "7450a372-154a-4a83-b0ba-48caa031c7c7"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Conv2D, Input, Activation, Lambda\n",
    "from keras.layers import BatchNormalization, MaxPooling2D, ZeroPadding2D, Add\n",
    "from keras.models import Model\n",
    "\n",
    "def resnet_layer(inputs, name, kernel_size=(1,1), num_filters=64, stride=1, padding='same', activation=True, batch_normalization=True):\n",
    "    conv = Conv2D(kernel_size=kernel_size, filters=num_filters, strides=stride, padding=padding, use_bias=False, name='C' + name, data_format='channels_first')\n",
    "    x = conv(inputs)\n",
    "    if batch_normalization == True:\n",
    "        x = BatchNormalization(name='bn' + name, axis=1)(x)\n",
    "    if activation == True:\n",
    "        x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(inputs, name, kernel_size=(1,1), stride=1, num_filters=64, shortcut_connection=False, first_stage=False):\n",
    "    num_filters_out = num_filters * 4\n",
    "    z = inputs\n",
    "    if shortcut_connection == True:\n",
    "        if first_stage == True:\n",
    "            stride = 1\n",
    "        else:\n",
    "            stride = 2\n",
    "            z = Lambda(lambda x: x[:, :, :-1, :-1], name=name + 'shortcut_slice')(inputs)\n",
    "        y = resnet_layer(z, kernel_size=kernel_size, num_filters=num_filters_out, stride=stride, activation=False, batch_normalization=True, name=name + '3')\n",
    "    else:\n",
    "        y = z\n",
    "\n",
    "    x = resnet_layer(inputs, kernel_size=kernel_size, num_filters=num_filters, stride=1, name=name + '0')\n",
    "    if stride == 2:\n",
    "        x = ZeroPadding2D(padding=((1, 0), (1, 0)), data_format='channels_first')(x)\n",
    "        x = resnet_layer(x, kernel_size=(3,3), num_filters=num_filters, stride=stride, padding='valid', name=name + '1')\n",
    "    else:\n",
    "        x = resnet_layer(x, kernel_size=(3,3), num_filters=num_filters, stride=stride, name=name + '1')\n",
    "    x = resnet_layer(x, kernel_size=kernel_size, num_filters=num_filters_out, stride=1, activation=False, name=name + '2')\n",
    "    sumed = Add()([x, y])\n",
    "    out = Activation('relu')(sumed)\n",
    "    return out\n",
    "\n",
    "def resnet50_c4(inputs):\n",
    "    blocks_per_stage = {0: 3, 1: 4, 2: 6}\n",
    "    num_filters = 64\n",
    "    x = ZeroPadding2D(padding=((3, 2), (3, 2)), data_format='channels_first')(inputs)\n",
    "    x = resnet_layer(inputs=x, kernel_size=(7,7), stride=2, padding='valid', name='1_bl0_0')\n",
    "    x = ZeroPadding2D(padding=((1, 0), (1, 0)), data_format='channels_first')(x)\n",
    "    x = MaxPooling2D((3,3), strides=2, padding='valid', name='maxpool', data_format='channels_first')(x)\n",
    "\n",
    "    c234 = []\n",
    "    for stage in range(3):\n",
    "        first_stage = False if stage != 0 else True\n",
    "        num_blocks = blocks_per_stage[stage]\n",
    "        for block in range(num_blocks):\n",
    "            shortcut_connection = False if block != 0 else True\n",
    "            basename = str(stage+2) + '_bl' + str(block) + '_'\n",
    "            x = residual_block(x, num_filters=num_filters, shortcut_connection=shortcut_connection, first_stage=first_stage, name=basename)\n",
    "        c234.append(x)\n",
    "        num_filters *= 2\n",
    "    return c234\n",
    "\n",
    "def rpn_head(c4):\n",
    "    conv_0 = Conv2D(kernel_size=(3,3), filters=1024, strides=1, padding='same', name='rpn_conv0', activation='relu', data_format='channels_first')(c4)\n",
    "    label_logits = Conv2D(kernel_size=(1,1), filters=15, strides=1, padding='same', name='trainable/rpn_class', data_format='channels_first')(conv_0)\n",
    "    box_logits = Conv2D(kernel_size=(1,1), filters=60, strides=1, padding='same', name='trainable/rpn_box', data_format='channels_first')(conv_0)\n",
    "    label_logits = Lambda(lambda x: tf.transpose(x, [0, 2, 3, 1]))(label_logits)\n",
    "    label_logits = Lambda(lambda x: tf.squeeze(x, 0))(label_logits)\n",
    "    shape = tf.shape(box_logits)\n",
    "    box_logits = Lambda(lambda x: tf.transpose(x, [0, 2, 3, 1]))(box_logits)\n",
    "    box_logits = Lambda(lambda x: tf.reshape(x, tf.stack([shape[2], shape[3], 15, 4])))(box_logits)\n",
    "    return [label_logits, box_logits]\n",
    "\n",
    "def build_model(input):\n",
    "    inputs = Input(tensor=input)\n",
    "    c2, c3, c4 = resnet50_c4(inputs)\n",
    "\n",
    "    # Object Detection\n",
    "    rpn_label_logits, rpn_box_logits = rpn_head(c4)\n",
    "    anchors = Lambda(narrow_to_c4, arguments={'anchor_boxes': get_all_anchors()})(c4)\n",
    "    image_shape2d = tf.shape(input)[2:]\n",
    "    pred_boxes_decoded = Lambda(decode_bbox_target, arguments={'anchors': anchors})(rpn_box_logits)\n",
    "    pred_boxes_decoded = Lambda(lambda x: tf.reshape(x, [-1, 4]))(pred_boxes_decoded)\n",
    "    rpn_label_logits = Lambda(lambda x: tf.reshape(x, [-1]))(rpn_label_logits)\n",
    "    proposal_boxes, proposal_scores = Lambda(generate_rpn_proposals, arguments={'img_shape': image_shape2d, 'pre_nms_topk': TEST_PRE_NMS_TOPK, 'post_nms_topk': TEST_POST_NMS_TOPK}, name='proposals')([pred_boxes_decoded, rpn_label_logits])\n",
    "    model = Model(inputs=inputs, outputs=[proposal_boxes, proposal_scores])\n",
    "    return model\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape=(1,3,None,None))\n",
    "model = build_model(input)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BmT9tl96SBti",
    "outputId": "9704151f-3cee-43f6-b721-26728ecb1985"
   },
   "outputs": [],
   "source": [
    "def normalize_image(img, mean, std):\n",
    "    mean = mean[::-1]\n",
    "    std = std[::-1]\n",
    "    new_img = (img - mean) / std\n",
    "    new_img = np.transpose(new_img, (2, 0, 1))\n",
    "    new_img = new_img[np.newaxis, :]\n",
    "    return new_img\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "# Defining the graph\n",
    "input = tf.placeholder(tf.float32, shape=(1, 3, None, None))\n",
    "model = build_model(input)\n",
    "proposal_boxes, proposal_scores = model(input)\n",
    "\n",
    "PIXEL_MEAN = [123.675, 116.28, 103.53]\n",
    "PIXEL_STD = [58.395, 57.12, 57.375]\n",
    "\n",
    "with sess.as_default():\n",
    "    model.load_weights('weights.h5', by_name=True)\n",
    "    print('*** Training images ***')\n",
    "    train_pred = {}\n",
    "    for filename in train_images:\n",
    "        print(filename)\n",
    "        normalized_img = normalize_image(train_images.get(filename)[0], mean=PIXEL_MEAN, std=PIXEL_STD)\n",
    "        bboxes, scores = sess.run([proposal_boxes, proposal_scores], feed_dict={input: normalized_img})\n",
    "        train_pred.setdefault(filename,[]).append(bboxes)\n",
    "    print('*** Testing images ***')\n",
    "    test_pred = {}\n",
    "    for filename in test_images:\n",
    "        print(filename)\n",
    "        normalized_img = normalize_image(test_images.get(filename)[0], mean=PIXEL_MEAN, std=PIXEL_STD)\n",
    "        bboxes, scores = sess.run([proposal_boxes, proposal_scores], feed_dict={input: normalized_img})\n",
    "        test_pred.setdefault(filename,[]).append(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save boxes in order to save time\n",
    "with open('./models/train_pred.pickle', 'wb') as fp:\n",
    "    pickle.dump(train_pred, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./models/test_pred.pickle', 'wb') as fp:\n",
    "    pickle.dump(test_pred, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MbQdzbPSBtl",
    "outputId": "177892b0-c884-421b-feb0-c0a6409ef2e7"
   },
   "source": [
    "# Build binary dataset\n",
    "Using ground truth as positive labels (real traffic signs) and all objects detected above as negative labels (bullshit and maybe some traffic signs).\n",
    "\n",
    "I guess this could be improved but for now it should work fine.\n",
    "\n",
    "\n",
    "There are about 1200 positives in gt.txt file.\n",
    "We can manipulate number of bboxes we add from one image so there are enough fake bboxes for the net to learn that. If we set it to 10 bboxes from each image we get 9000 fake bboxes and 1200 good bboxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MbQdzbPSBtl",
    "outputId": "177892b0-c884-421b-feb0-c0a6409ef2e7"
   },
   "outputs": [],
   "source": [
    "# reload boxes from pickle\n",
    "with open('./models/train_pred.pickle', 'rb') as fp:\n",
    "    train_pred = pickle.load(fp)\n",
    "with open('./models/test_pred.pickle', 'rb') as fp:\n",
    "    test_pred = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MbQdzbPSBtl",
    "outputId": "177892b0-c884-421b-feb0-c0a6409ef2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.9 s, sys: 60.9 ms, total: 17 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_bin_labels(number_of_images, n_bbox):\n",
    "    with open('./data/bin_labels.txt', 'w') as file:\n",
    "        \n",
    "        # add negatives\n",
    "        counter = 0\n",
    "        for i, v in {**train_pred, **test_pred}.items():\n",
    "            \n",
    "            gr_bboxes = []\n",
    "            with open('../FullIJCNN2013/gt.txt', 'r') as gr_truth:\n",
    "                for line in gr_truth:\n",
    "                    line = line.split(';')\n",
    "                    if (line[0] == i.split('/')[-1]):\n",
    "                        gr_bboxes.append(line[1:5])\n",
    "                        \n",
    "            \n",
    "            # save each detected bbox to file and add label\n",
    "            for bbox in v[0][:n_bbox]:\n",
    "                \n",
    "                #filter out some boxes before tagging them as negatives\n",
    "                dx = int(bbox[0])-int(bbox[2])\n",
    "                dy = int(bbox[1])-int(bbox[3])\n",
    "                ratio = abs(dy/dx)\n",
    "                if ratio<1:\n",
    "                    ratio=1/ratio\n",
    "                if ratio>1.2:\n",
    "                    continue                \n",
    "                \n",
    "                temp = []\n",
    "                for k in range(len(gr_bboxes)):\n",
    "                    #print(i.split('/')[-1], gr_bboxes[k])\n",
    "                    #print(np.array([gr_bboxes[k]]).astype('float32').shape)\n",
    "                    #print(np.array([bbox]).shape)\n",
    "                    iou_var = iou(np.array([gr_bboxes[k]]).astype('float32'), np.array([bbox]))\n",
    "                    #print(float(iou_var[0]))\n",
    "                    temp.append(float(iou_var[0]))\n",
    "                \n",
    "                \n",
    "                if max(temp, default=0)>0.1:\n",
    "                    continue\n",
    "#                     file.write(\n",
    "#                         i.split('/')[-1]+';'+\n",
    "#                         str(int(bbox[0]))+';'+\n",
    "#                         str(int(bbox[1]))+';'+\n",
    "#                         str(int(bbox[2]))+';'+\n",
    "#                         str(int(bbox[3]))+';2')\n",
    "#                     file.write('\\n')\n",
    "                else:\n",
    "                    file.write(\n",
    "                        i.split('/')[-1]+';'+\n",
    "                        str(int(bbox[0]))+';'+\n",
    "                        str(int(bbox[1]))+';'+\n",
    "                        str(int(bbox[2]))+';'+\n",
    "                        str(int(bbox[3]))+';0')\n",
    "                    file.write('\\n')\n",
    "\n",
    "\n",
    "#                 file.write(\n",
    "#                     i.split('/')[-1]+';'+\n",
    "#                     str(int(bbox[0]))+';'+\n",
    "#                     str(int(bbox[1]))+';'+\n",
    "#                     str(int(bbox[2]))+';'+\n",
    "#                     str(int(bbox[3]))+';0')\n",
    "#                 file.write('\\n')\n",
    "                \n",
    "                    \n",
    "                \n",
    "            counter+=1\n",
    "            if counter >= number_of_images: break\n",
    "\n",
    "        # add positives\n",
    "        with open('../FullIJCNN2013/gt.txt', 'r') as positives:\n",
    "            for line in positives:\n",
    "                line = line.split(';')\n",
    "                line[-1] = '1'\n",
    "                file.write(';'.join(line)+'\\n')\n",
    "\n",
    "number_of_images = 900 # use small number for testing\n",
    "n_bbox = 1000 # number of negative bboxes from one image \n",
    "get_bin_labels(number_of_images, n_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147540 ./data/bin_labels_sorted.txt\n",
      "00000.ppm;0;0;152;155;0\n",
      "00000.ppm;0;0;425;486;0\n",
      "00000.ppm;0;102;451;600;0\n",
      "00000.ppm;0;253;379;600;0\n",
      "00000.ppm;0;297;113;414;0\n",
      "00000.ppm;0;314;22;340;0\n",
      "00000.ppm;0;314;236;516;0\n",
      "00000.ppm;0;337;117;459;0\n",
      "00000.ppm;0;458;170;600;0\n",
      "00000.ppm;10;358;40;390;0\n",
      "00899.ppm;909;434;1012;540;0\n",
      "00899.ppm;914;441;982;515;0\n",
      "00899.ppm;922;455;948;477;0\n",
      "00899.ppm;937;456;964;479;0\n",
      "00899.ppm;938;432;962;453;0\n",
      "00899.ppm;954;445;977;470;0\n",
      "00899.ppm;954;491;978;519;0\n",
      "00899.ppm;955;462;1020;518;0\n",
      "00899.ppm;957;476;1020;531;0\n",
      "00899.ppm;974;505;1020;559;0\n"
     ]
    }
   ],
   "source": [
    "! sort ./data/bin_labels.txt --output=./data/bin_labels_sorted.txt\n",
    "! wc -l ./data/bin_labels_sorted.txt\n",
    "! head -n 10 ./data/bin_labels_sorted.txt\n",
    "! tail -n 10 ./data/bin_labels_sorted.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147540 ./data/bin_labels_sorted.txt\n",
      "97022-00599.ppm;900;374;926;405;0\n",
      "97023-00599.ppm;924;345;952;371;0\n",
      "97024-00599.ppm;92;297;210;423;0\n",
      "97025-00599.ppm;95;128;528;600;0\n",
      "97026-00599.ppm;992;233;1013;255;0\n",
      "97027:00600.ppm;0;0;154;157;0\n",
      "97028-00600.ppm;0;0;408;353;0\n",
      "97029-00600.ppm;0;0;528;563;0\n",
      "97030-00600.ppm;0;272;288;600;0\n",
      "97031-00600.ppm;0;321;236;531;0\n",
      "97032-00600.ppm;0;414;143;549;0\n"
     ]
    }
   ],
   "source": [
    "# this is just to  get numbers for traffic signs range in train and test set\n",
    "! wc -l ./data/bin_labels_sorted.txt\n",
    "! grep \"00600.ppm\" -B 5 -A 5 -m 1 ./data/bin_labels_sorted.txt --line-number"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Assignment_3_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
